import file
import hash.wyhash as wyhash
import json

import yang.parser
import yang.schema
import transform_explicit_cases
import transform_remove_empty_refines
import transform_repair_patterns


def eq_optional[T(Eq)](a: ?T, b: ?T) -> bool:
    return a is not None and b is not None and a == b or a is None and b is None


def optional_str[T](v: ?T, default: str = "None") -> str:
    return str(v) if v is not None else default


class NameRevMap[T](object):
    items: dict[str, (?str, T)]

    def __init__(self):
        self.items = {}

    def add(self, name: str, revision: ?str, val: T):
        try:
            old_revision, old_val = self.items[name]
        except KeyError:
            pass
        else:
            if not eq_optional(revision, old_revision):
                raise ValueError("Another revision of item {name} already present, old: {optional_str(old_revision)}, new: {optional_str(revision)}")
        self.items[name] = (revision, val)

    def get(self, name: str, revision: ?str = None) -> T:
        actual_revision, val = self.items[name]
        if revision is not None and revision != actual_revision:
            raise ValueError("Mismatching revision requested: {optional_str(revision)}, actual: {optional_str(actual_revision)}")
        return val

    def pop(self, name: str, revision: ?str = None) -> T:
        val = self.get(name, revision)
        del self.items[name]
        return val

    def pop_any(self) -> T:
        _n, (_r, val) = self.items.popitem()
        return val


extension NameRevMap[T](Collection[(str, (?str, T))]):
    def __iter__(self) -> Iterator[(str, (?str, T))]:
        return self.items.items()

    @staticmethod
    def __fromiter__(iterable):
        # actonc: mut must be a subclass of pure
        # new = NameRevMap()
        # for name, (revision, item) in iterable:
        #     new.add(name, revision, item)
        # return new
        raise NotImplementedError()

    def __len__(self) -> int:
        return len(self.items)


def parse_statements(yang_sources: list[str], strict_quoting: bool=False) -> list[yang.schema.Statement]:
    """Parse a list of YANG source strings into Statement trees

    This function takes YANG module source code as strings and parses them into
    Statement tree representations. Each YANG source is parsed independently.
    """
    return [yang.parser.parse(src, strict_quoting) for src in yang_sources]


def parse_modules(yang_sources: Iterable[yang.schema.Statement]) -> NameRevMap[yang.schema.Module]:
    """Parse and merge the YANG Statement trees into Module nodes

    This function takes a (iterable of) Statement trees and converts them into a
    Module or Submodule node. Then it merges the submodule contents into the
    parent module while remapping prefixes if needed to avoid ambiguities.

    Returns a name-and-revision map of Module nodes.
    """
    modules: NameRevMap[yang.schema.Module] = NameRevMap()
    submodules: NameRevMap[yang.schema.Submodule] = NameRevMap()

    for yang_source in yang_sources:
        yang_module = yang.schema.stmt_to_snode(yang_source)
        # Normalize schema: wrap standalone data nodes in "choice" with explicit "case"
        transform_explicit_cases.create_explicit_cases(yang_module)
        # Remove empty (no statements in block) refinements from the schema tree.
        # TODO: this pre-compile transform is not required for the generic use
        # case because applying an empty refinement is a no-op method call. It
        # does however filter out invalid refinements (non-existant path) in
        # Cisco IOS XE models ...  Ideally we would let the users apply any
        # SchemaNode pre-compile transforms by splitting this function into
        # smaller steps, like we already do with DNode
        transform_remove_empty_refines.remove_empty_refines(yang_module)
        # Repair known broken yang model string patterns
        transform_repair_patterns.repair_patterns(yang_module)
        if isinstance(yang_module, yang.schema.Module):
            modrev = yang_module.get_modrev()
            modules.add(modrev.modname, modrev.rev, yang_module)
        elif isinstance(yang_module, yang.schema.Submodule):
            modrev = yang_module.get_modrev()
            submodules.add(modrev.modname, modrev.rev, yang_module)

    # merge submodules into their main module
    for _n, (_r, m) in modules:
        combined_import_prefixes: NameRevMap[str] = NameRevMap()
        for import_ in m.import_:
            combined_import_prefixes.add(import_.module, import_.revision_date, import_.prefix)

        for include in m.include:
            try:
                submod = submodules.get(include.module, include.revision_date)
            except KeyError:
                raise ValueError("{m.name} - submodule {include.module} not found.")
            else:
                # Track all prefix remappings needed when merging submodule into parent:
                # 1. Submodule uses different prefix for parent module (belongs-to)
                # 2. Same module imported with different prefix in parent vs submodule
                # 3. Different modules imported with same prefix in parent vs submodule
                prefix_remaps: dict[str, str] = {}

                # Case 1: Submodule uses different prefix for parent module
                if submod.belongs_to.prefix != m.prefix:
                    prefix_remaps[submod.belongs_to.prefix] = m.prefix

                for sub_import in submod.import_:
                    try:
                        import_prefix = combined_import_prefixes.get(sub_import.module, sub_import.revision_date)
                    except KeyError:
                        # New import - not yet in parent
                        prefix_to_use = sub_import.prefix

                        # Case 3: Check if this prefix is already used for a different module
                        for mod_name, (rev, pfx) in combined_import_prefixes:
                            if pfx == sub_import.prefix and mod_name != sub_import.module:
                                prefix_to_use = "{sub_import.prefix}-{submod.name}"
                                prefix_remaps[sub_import.prefix] = prefix_to_use
                                break

                        combined_import_prefixes.add(sub_import.module, sub_import.revision_date, prefix_to_use)

                        new_import = yang.schema.Import(sub_import.module,
                                                        description=sub_import.description,
                                                        prefix=prefix_to_use,
                                                        reference=sub_import.reference,
                                                        revision_date=sub_import.revision_date,
                                                        exts=sub_import.exts,
                                                        ns=sub_import.ns,
                                                        parent=m)

                        m.import_.append(new_import)
                    else:
                        # Case 2: Same module already imported by parent (or another submodule)
                        if sub_import.prefix != import_prefix:
                            # Remap to use parent's prefix for this module
                            prefix_remaps[sub_import.prefix] = import_prefix
                        # else: # Same module, same prefix. We're fine!

                for c in submod.children:
                    # Set parent attribute for direct children only
                    c.parent = m

                    # Always update namespace qualifiers to parent module's values
                    c.update_namespace_qualifiers(m.namespace, m.prefix, m.name)

                    # Apply all prefix remappings (parent module and imports)
                    for old_pfx, new_pfx in prefix_remaps.items():
                        c.remap_prefix_references(old_pfx, new_pfx)

                    m.children.append(c)

                # Update augment nodes
                for aug in submod.augment:
                    # Set parent attribute
                    aug.parent = m

                    # Update the augment node's namespace qualifiers
                    aug.update_namespace_qualifiers(m.namespace, m.prefix, m.name)

                    # Apply all prefix remappings to augment paths and content
                    for old_pfx, new_pfx in prefix_remaps.items():
                        aug.target_node = yang.schema._remap_path_prefix(aug.target_node, old_pfx, new_pfx)
                        aug.remap_prefix_references(old_pfx, new_pfx)

                m.augment.extend(submod.augment)
                # discard contact
                # discard description

                # Remap deviation paths if needed
                for dev in submod.deviation:
                    remapped_dev = dev
                    for old_pfx, new_pfx in prefix_remaps.items():
                        remapped_dev = yang.schema._remap_path_prefix(remapped_dev, old_pfx, new_pfx)
                    m.deviation.append(remapped_dev)

                # Update extension nodes
                for ext in submod.extension_:
                    # Set parent attribute
                    ext.parent = m

                    # Update namespace qualifiers
                    ext.update_namespace_qualifiers(m.namespace, m.prefix, m.name)

                    # Apply all prefix remappings
                    for old_pfx, new_pfx in prefix_remaps.items():
                        ext.remap_prefix_references(old_pfx, new_pfx)

                m.extension_.extend(submod.extension_)

                # discard organization
                # discard reference
                # discard revision

                # Update feature nodes
                for feat in submod.feature:
                    # Set parent attribute
                    feat.parent = m

                    # Update namespace qualifiers
                    feat.update_namespace_qualifiers(m.namespace, m.prefix, m.name)

                    # Apply all prefix remappings
                    for old_pfx, new_pfx in prefix_remaps.items():
                        feat.remap_prefix_references(old_pfx, new_pfx)

                m.feature.extend(submod.feature)

                m.exts.extend(submod.exts)

        m.include = []
    return modules


def compile_modules(modules: NameRevMap[yang.schema.Module]) -> list[yang.schema.Module]:
    """Compile a list of YANG modules

    This function compiles the list of input Module nodes. Compiling a module
    recursively calls the .compile() method on the node and its children. The
    result is a new schema tree where we expand groupings, apply augmentations,
    resolve typedefs, ...

    Returns a list of Module nodes with the non-data nodes (Uses, Grouping,
    Typedef, ...) still present.
    """
    # Compile in dependency by import depth-first search
    ctx = yang.schema.Context()
    build_stack: list[(yang.schema.Module, list[yang.schema.Import])] = []
    while True:
        if len(build_stack) > 0:
            m, unresolved_imports = build_stack.pop()
            if len(unresolved_imports) > 0:
                # Push first remaining import to build stack
                m_import = unresolved_imports.pop()
                build_stack.append((m, unresolved_imports))
                try:
                    imported_module = modules.pop(m_import.module, m_import.revision_date)
                except KeyError:
                    pass # Import either already processed, missing or cyclic
                else:
                    build_stack.append((imported_module, list(imported_module.import_)))
            else:
                try:
                    mc = m.compile(ctx)
                except Exception as ex:
                    raise ValueError("{m.name} - Compile - Failed: {ex.error_message}")
                else:
                    if isinstance(mc, yang.schema.Module):
                        ctx.add_module(mc)
                    else:
                        raise ValueError(m.name + " - Compile - Failed: not a module")
        elif len(modules) > 0:
            m = modules.pop_any()
            build_stack.append((m, list(m.import_)))
        else:
            break

    no_rev_modules: list[yang.schema.Module] = []
    for mod_rev, m in ctx.modules.items():
        mod_rev_rev = mod_rev.rev
        if mod_rev_rev is None:
            no_rev_modules.append(m)
    return no_rev_modules

def compile_to_dmodules(modules: list[yang.schema.Module]) -> list[yang.schema.DModule]:
    """Compile a list of Module to DModule nodes

    This is an intermediate step in compiling the schema, as what we usually do
    is then combine those DModule objects into a single DRoot object.
    """
    dmodules: list[yang.schema.DModule] = []
    for m in modules:
        dm = m.to_dnode()
        if isinstance(dm, yang.schema.DModule):
            dmodules.append(dm)
    return dmodules


def compile_to_droot(dmodules: list[yang.schema.DModule]) -> yang.schema.DRoot:
    """Compile a list of DModules into a DRoot object

    This function is the final step in compiling the schema. It takes a list of
    DModules and combines them into a single DRoot object.
    """
    return yang.schema.DRoot.from_modules(dmodules)


def _load_cached_statement(fc: file.FileCap, cache_file: str) -> ?yang.schema.Statement:
    """Try to load cached Statement from JSON file"""
    rfc = file.ReadFileCap(fc)

    rf = None
    try:
        rf = file.ReadFile(rfc, cache_file)
    except FileNotFoundError:
        return None

    if rf is not None:
        json_content = rf.read().decode()
        rf.close()

        json_data = None
        try:
            json_data = json.decode(json_content)
        except ValueError:
            return None

        if json_data is not None:
            try:
                return yang.schema.Statement.from_dict(json_data)
            except Exception:
                return None


def _save_statement_to_cache(fc: file.FileCap, cache_file: str, stmt: yang.schema.Statement):
    """Save Statement to cache as JSON"""
    wfc = file.WriteFileCap(fc)
    json_content = json.encode(stmt.to_dict(), pretty=True)
    wf = file.WriteFile(wfc, cache_file)
    wf.write(json_content.encode())
    wf.close()


def compile_with_cache(yang_sources: list[str], strict_quoting=True, fc: file.FileCap) -> yang.schema.DRoot:
    """Parse and compile a set of YANG modules and submodules into a derived schema tree, but with Statement caching.

    This function is equivalent to the compile function, except that it caches
    the parsed Statement trees as JSON files to avoid re-parsing unchanged YANG
    sources.
    """
    fs = file.FS(fc)
    cache_dir = [fs.homedir(), ".cache", "ayang"]
    fs.mkdir(file.join_path(cache_dir))

    statements: list[yang.schema.Statement] = []

    for src in yang_sources:
        content_hash = str(wyhash.hash(0, src.encode()))
        cache_filename = "{content_hash}.json"
        cache_path = file.join_path(cache_dir + [cache_filename])

        stmt = _load_cached_statement(fc, cache_path)

        if stmt is not None:
            statements.append(stmt)
        else:
            new_stmt = yang.parser.parse(src, strict_quoting)
            _save_statement_to_cache(fc, cache_path, new_stmt)
            statements.append(new_stmt)

    return compile_to_droot(compile_to_dmodules(compile_modules(parse_modules(statements))))


def compile_from_stmt(yang_statements: list[yang.schema.Statement]):
    return compile_to_droot(compile_to_dmodules(compile_modules(parse_modules(yang_statements))))


def compile(yang_sources: list[str], strict_quoting=True) -> yang.schema.DRoot:
    """Parse and compile a set of YANG modules and submodules into a derived schema tree

    The derived schema tree combines all processed modules and submodules into
    a single DRoot. Direct descendats of DRoot are the data nodes, not the
    modules. The derived schema tree consists of DNode objects for data nodes
    only - no grouping, uses, typedef and indentity statements.
    """
    return compile_to_droot(
        compile_to_dmodules(
            compile_modules(
                parse_modules(
                    parse_statements(yang_sources, strict_quoting)
                )
            )
        )
    )


def schema_from_src(src: str) -> yang.schema.SchemaNode:
    """Parse a single YANG schema from source code into the SchemaNode representation
    """
    return yang.schema.stmt_to_snode(yang.parser.parse(src))
